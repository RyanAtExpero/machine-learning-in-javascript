{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "In machine learning system we often need to pull in data from various sources and have to capture a large set of features in order to \"span the input space\". \n",
    "\n",
    "That is in order to give the algorithm an opportunity to see and enccode all of teh potential variation in the input space that it needs to learn from, without leaving variables/dimensions of the inputs space unexplored.\n",
    "\n",
    "For example, what if we had not includes measures like `Hue` or `Flavinoids` in our input feature set? surely this would have left an important factor in analying the wines unmeasured.\n",
    "\n",
    "## Large Feature Spaces\n",
    "\n",
    "So in machine learning the process of gathering measurements, pre-processing these and even making different sub measurements on those is the process of \"feature engineering\". We're not going to cover that today as it's an open ended area. \n",
    "\n",
    "However, we are going to note that there is a tendency to construct large feature spaces in an effort to include all teh necessary information. Feature vectors with 100's of elements are common.\n",
    "\n",
    "that leaves questions\n",
    "\n",
    " - Where does information reside in that space?\n",
    " - Which features correlate with each other?\n",
    " - Where is there redundancy?\n",
    " \n",
    "Benefits:\n",
    "\n",
    " - more likely to find linear decision boundaries with high N (we'll look at this more in supervised)\n",
    " - better span the input space\n",
    " \n",
    "And challenges\n",
    "\n",
    " - computational cost increases\n",
    " - [overfitting](https://en.wikipedia.org/wiki/Overfitting) with non linear methods\n",
    " \n",
    "\n",
    "### Dimensionality reduction is about....\n",
    "\n",
    "... finding a more compact space, with fewer demensions that still contains the majority of the information from the original space. This lower dimensional space is often called an \"embedding\" and can be linear or non-linear transformations of the original.\n",
    "\n",
    "![dimensionality reduction](images/slide_dimred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "PCA is a well known and effective dimensionalty reduction technique. It's relatively simple but still effective in a lot of circumstances. It is linear and global which has advantages but also limitations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![scatter](images/pca-scatter.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$(A - \\lambda I)v=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![eigenvectors](images/pca-eigen.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA to our data ahead of KMeans \n",
    "\n",
    "So now let's cirle back and bring our $R^{13}$ KMeans code over from the last notebook. \n",
    "\n",
    "This time we are going to insert an additional step and run PCA before kmeans.\n",
    "\n",
    "We then look at the eigenvalues to decide whichare the most important dimensions in the eigenspace.\n",
    "\n",
    "And we select the M first principle components for usein kmeans.\n",
    "\n",
    "In order to do that we actually need to project our dataset into the new space, and truncatethe vectors to the M most important dimensions that we have decided on.\n",
    "\n",
    "\n",
    "The docs for PCA in mljs are [here](https://github.com/mljs/pca)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var PCA = require('ml-pca');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, now we have a more compact space tht still describes the majority of the informaiton in our dataset.\n",
    "\n",
    "This is probaly the simplest form of *Embedding* that you can get.\n",
    "\n",
    "Now let's apply kmeans again and see what happens! time for some (ctrl-c,ctrl-v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Reading\n",
    "\n",
    " - [excellent article on teh curse of dimensionality](http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/)\n",
    " - [tSNE]()\n",
    " - [autoencoders]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "jp-Babel (Node.js)",
   "language": "babel",
   "name": "babel"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "8.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
